{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose of notebook:\n",
        "\n",
        "This notebook is designed to pull down test TIU formatted notes from Azure storage so that the research/development instance of the codebase can be run. To run this notebook, you can run each cell until the end. \n",
        "\n",
        "### Errors:\n",
        "If you run into any errors, most of the times the solution is just to try again or stop the kernel and restart. In rare cases where even that doesn't work, you can try to delete this notebook and get a fresh copy from within Suzanne Tamang's user folder. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "main_start = time.time()\n",
        "\n",
        "# end = time.time()\n",
        "\n",
        "print('time at stage {:.6}'.format(time.time() - main_start))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "time at stage 6.1512e-05\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "ae14eb3c-7691-4c6c-82aa-623abfc0ca9a",
          "showTitle": false,
          "title": ""
        },
        "gather": {
          "logged": 1684793820755
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "d13fb852-4054-4061-a855-d7847db9a6c8",
          "showTitle": false,
          "title": ""
        },
        "gather": {
          "logged": 1684793821467
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.functions import isnan, count, when, col, desc, udf, col, sort_array, asc, avg, to_timestamp, size\n",
        "from pyspark.sql.functions import substring, regexp_replace, trim, row_number, monotonically_increasing_id, rand\n",
        "from pyspark.sql.functions import concat_ws, expr, lit, regexp_extract, collect_list, explode\n",
        "from pyspark.sql.functions import sum as Fsum\n",
        "# from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import IntegerType, BooleanType\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import Window as W\n",
        "# from pyspark.sql.types import *\n",
        "from functools import reduce  # For Python 3.x\n",
        "# from pyspark.sql import DataFrame\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import udf, struct\n",
        "from pyspark.sql.functions import udf, explode\n",
        "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
        "from pyspark.sql.types import ArrayType, IntegerType\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Datastore, Dataset, Keyvault\n",
        "from azureml.contrib.dataset import FileHandlingOption\n",
        "from azureml.core import Dataset\n",
        "from azureml.data.datapath import DataPath\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core import ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import MpiConfiguration\n",
        "from azureml.core import Environment\n",
        "from azureml.core import Experiment\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.telemetry import set_diagnostics_collection\n",
        "import azureml.core\n",
        "import math"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1684793821780
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.functions import isnan, count, when, col, desc, udf, col, sort_array, asc, avg, to_timestamp, size\n",
        "from pyspark.sql.functions import substring, regexp_replace, trim, row_number, monotonically_increasing_id, rand\n",
        "from pyspark.sql.functions import concat_ws, expr, lit, explode\n",
        "from pyspark.sql.functions import sum as Fsum\n",
        "# from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import IntegerType, BooleanType\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import Window as W\n",
        "# from pyspark.sql.types import *\n",
        "from functools import reduce  # For Python 3.x\n",
        "# from pyspark.sql import DataFrame\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
        "# from pyspark.sql import Window"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "361fdbd8-1007-4c68-b4c8-57910ba3e208",
          "showTitle": false,
          "title": ""
        },
        "gather": {
          "logged": 1684793821966
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import udf, struct\n",
        "from pyspark.sql.functions import udf, explode\n",
        "from pyspark.sql.types import ArrayType, IntegerType, StringType"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "98beb54e-6248-4d8e-a5db-6f3eb65c17c6",
          "showTitle": false,
          "title": ""
        },
        "gather": {
          "logged": 1684793822169
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, date_trunc\n",
        "from pyspark.sql.functions import  min as min_\n",
        "from pyspark.sql.functions import  max as max_\n",
        "from pyspark.sql.functions import  avg as avg_"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "847b8929-1733-49a5-b700-13736292cf22",
          "showTitle": false,
          "title": ""
        },
        "gather": {
          "logged": 1684793822363
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import concat_ws, expr, lit, regexp_extract, collect_list, explode\n",
        "import math\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import udf, struct\n",
        "from pyspark.sql.functions import udf, explode\n",
        "from pyspark.sql.functions import row_number, monotonically_increasing_id, flatten\n",
        "from pyspark.sql.types import ArrayType, IntegerType"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "97622108-93cc-4853-86d7-e271168863af",
          "showTitle": false,
          "title": ""
        },
        "gather": {
          "logged": 1684793822648
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "import re\n",
        "re.sub(r'a', 'b', 'banana')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "'bbnbnb'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "7771c823-0afd-45ca-8e5d-b29ab02372b2",
          "showTitle": false,
          "title": ""
        },
        "gather": {
          "logged": 1684793822945
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['PYSPARK_DRIVER_PYTHON'] = '/anaconda/envs/azureml_py38/bin/python'\n",
        "os.environ['PYSPARK_PYTHON'] = '/anaconda/envs/azureml_py38/bin/python'\n",
        "os.environ['RSLEX_DIRECT_VOLUME_MOUNT'] = 'true'"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1684793823530
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Datastore, Dataset \n",
        "from azureml.data.datapath import DataPath\n",
        "from pathlib import Path\n",
        "from azureml.core.authentication import AzureCliAuthentication \n",
        "import tempfile\n",
        "import os\n",
        "import shutil\n",
        "# retrieve Azure workspace config settings. The first time this is run on a compute instance, you will need to authenticate through terminal (run 'az login') which will prompt you to authenticate through browser/code.\n",
        "# use this is if 'ws = Workspace.from_config() is not working below\n",
        "cli_auth = AzureCliAuthentication()"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1684793823706
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import AzureCliAuthentication \n",
        "\n",
        "cli_auth = AzureCliAuthentication()\n",
        "\n",
        "!az login"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[93mTo sign in, use a web browser to open the page https://microsoft.com/deviceloginus and enter the code AR5SHSPGP to authenticate.\u001b[0m\n[\n  {\n    \"cloudName\": \"AzureUSGovernment\",\n    \"homeTenantId\": \"f7c49e36-971b-42c7-b244-a88eed6c0bf6\",\n    \"id\": \"97107ad7-bc7f-4696-a5c2-fd242faef941\",\n    \"isDefault\": true,\n    \"managedByTenants\": [\n      {\n        \"tenantId\": \"b84a3698-77b0-45ce-ae60-6d735f43edbe\"\n      }\n    ],\n    \"name\": \"CDW-GOV-INTERNAL\",\n    \"state\": \"Enabled\",\n    \"tenantId\": \"f7c49e36-971b-42c7-b244-a88eed6c0bf6\",\n    \"user\": {\n      \"name\": \"Nikhil.Sharma2@va.gov\",\n      \"type\": \"user\"\n    }\n  }\n]\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1684793871299
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "raw",
      "source": [
        "!az login"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# ws = Workspace.from_config()\n",
        "# my_secret = os.environ.get(\"MY_SECRET\")\n",
        "ws = Workspace.from_config(auth=cli_auth)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1684793871499
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rawzone = Datastore.get(ws, datastore_name='rawzonedata')\n",
        "workspacezone = Datastore.get(ws, datastore_name='workspaceblobstore')\n",
        "# dssbzone = Datastore.get(ws, datastore_name='dssbzonefs')\n",
        "print('time at stage {:.6}'.format(time.time() - main_start))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "time at stage 50.9858\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1684793871868
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastores = ws.datastores\n",
        "for name, datastore in datastores.items():\n",
        "    print(name, datastore.datastore_type)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "projectdatafs_nocreds AzureDataLakeGen2\nrefinedzonefs_nocreds AzureDataLakeGen2\nimages_datastore AzureBlob\nehost_temp AzureFile\nccts_hyperscale AzureSqlDatabase\nworkspaceartifactstore AzureBlob\nazureml_globaldatasets AzureBlob\nehost AzureFile\nvac20asacdwml402_azureml AzureBlob\nrefinedzonefs AzureDataLakeGen2\ndssbzonefs AzureDataLakeGen2\nprojectdatafs AzureDataLakeGen2\nrawzonedata AzureDataLakeGen2\nworkspacefilestore AzureFile\nworkspaceblobstore AzureBlob\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1684793872234
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delta_rootUrl = '/tmp/workspacezone'\n",
        "delta_datasets = 'TIU_202204to202209_visit_document_note_noXPNA2'"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1684793872419
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_ds = Dataset.File.from_files(path= \\\n",
        "    [DataPath(datastore=workspacezone, path_on_datastore=\n",
        "              (delta_datasets))])"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1684793875327
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mount_context = dataset_ds.mount(mount_point=delta_rootUrl)\n",
        "mount_context.start()  # this will mount the file streams"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Failed to ensure mount point \"/tmp/workspacezone\" due to exception of type FileExistsError with message [Errno 17] File exists: '/tmp/workspacezone', proceeding with mount attempt.\nfuse: bad mount point `/tmp/workspacezone': Transport endpoint is not connected\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/fuse/cli.py\", line 89, in <module>\n    _main()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/fuse/cli.py\", line 75, in _main\n    clex_mount(dataflow, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/fuse/dprepfuse.py\", line 623, in clex_mount\n    FUSE(fuse_opts, mount_point, foreground=True, **additional_options)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/fuse/vendor/fuse.py\", line 714, in __init__\n    raise RuntimeError(err)\nRuntimeError: 1\n"
        },
        {
          "output_type": "error",
          "ename": "FuseProcessTerminatedException",
          "evalue": "\nError Code: Unexpected\nError Message: | session_id=046fd4ac-7627-40dc-b290-fa79aac98a5e",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFuseProcessTerminatedException\u001b[0m            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mount_context \u001b[38;5;241m=\u001b[39m dataset_ds\u001b[38;5;241m.\u001b[39mmount(mount_point\u001b[38;5;241m=\u001b[39mdelta_rootUrl)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmount_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# this will mount the file streams\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/fuse/daemon.py:110\u001b[0m, in \u001b[0;36mMountContext.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    106\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mount the file streams.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    This is equivalent to calling the MountContext.__enter__ instance method.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/api/_loggerfactory.py:273\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _LoggerFactory\u001b[38;5;241m.\u001b[39mtrack_activity(logger, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, DEFAULT_ACTIVITY_TYPE, custom_dimensions) \u001b[38;5;28;01mas\u001b[39;00m activityLogger:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(activityLogger, ACTIVITY_INFO_KEY) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, ERROR_CODE_KEY):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/fuse/daemon.py:131\u001b[0m, in \u001b[0;36mMountContext.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmount\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_span_context,\n\u001b[1;32m    130\u001b[0m                                       user_facing_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLaunching Mount Daemon\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 131\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_mount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/fuse/daemon.py:332\u001b[0m, in \u001b[0;36mMountContext._retry_mount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMounting daemon process attempt \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(current_attempt))\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mount_using_daemon()\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_until_mounted\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FuseTimeoutException:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/fuse/daemon.py:256\u001b[0m, in \u001b[0;36mMountContext._wait_until_mounted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(error_msg)\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FuseTimeoutException(error_msg)\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_child_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m sleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sleep_time \u001b[38;5;241m*\u001b[39m attempt)\n\u001b[1;32m    258\u001b[0m attempt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/dataprep/fuse/daemon.py:289\u001b[0m, in \u001b[0;36mMountContext._ensure_child_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    288\u001b[0m _LoggerFactory\u001b[38;5;241m.\u001b[39mtrace(logger, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMount child process has exited with code \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(exit_code))\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m FuseProcessTerminatedException(exit_code)\n",
            "\u001b[0;31mFuseProcessTerminatedException\u001b[0m: \nError Code: Unexpected\nError Message: | session_id=046fd4ac-7627-40dc-b290-fa79aac98a5e"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1684793900437
        }
      }
    },
    {
      "cell_type": "raw",
      "source": [
        "!sudo umount /tmp/workspacezone"
      ],
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": [
        "mount_context.stop() "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ls /tmp/workspacezone/metadata"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901186
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666067510549
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls /tmp/workspacezone/tsv/*"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1684793901203
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run all above here, below is how to concat loop upload "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ls /tmp/workspacezone/metadata/lastmodifieddatetime_month=202205"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "gather": {
          "logged": 1684793901218
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901235
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filelist = glob.glob('/tmp/workspacezone/metadata/*.txt')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901251
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputFoldermetadata = '/tmp/visit_document_note/metadata'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901269
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/tmp/visit_document_note/metadata')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $outputFoldermetadata"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for count, file in enumerate(filelist):\n",
        "    filename = file.split('/')[4]\n",
        "    print(f'{count} n {filename} u {file}')\n",
        "    # os.system(f\"cat {file}/p* > {outputFoldermetadata}/{filename}.txt\")\n",
        "    # os.system(f\"ls {outputFoldermetadata}\")\n",
        "    \n",
        "    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901306
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filelist = glob.glob('/tmp/workspacezone/tsv/*.txt')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901322
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputFoldermetadata = '/tmp/visit_document_note/tsv'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901339
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/tmp/visit_document_note/tsv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901355
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $outputFoldermetadata"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for count, file in enumerate(filelist):\n",
        "    filename = file.split('/')[4]\n",
        "    print(f'{count} n {filename} u {file}')\n",
        "    # os.system(f\"cat {file}/p* > {outputFoldermetadata}/{filename}.txt\")\n",
        "    # os.system(f\"ls {outputFoldermetadata}\")\n",
        "    \n",
        "    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1684793901375
        }
      }
    },
    {
      "cell_type": "raw",
      "source": [
        "#Initiate Spark\n",
        "\n",
        "# Enter RAM of current compute\n",
        "ram = 2005\n",
        "driver_mem = int(ram * 0.9)\n",
        "cores = 128\n",
        "partitions = cores * 3\n",
        "\n",
        "print(\"Connect to Spark\")\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"SparkApp\") \\\n",
        "    .master('local[*]') \\\n",
        "    .config('spark.driver.memory', f'{driver_mem}g') \\\n",
        "    .config('spark.sql.shuffle.partitions', f'{partitions}') \\\n",
        "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
        "    .config(\"spark.executor.memory\",\"8g\") \\\n",
        "    .config(\"spark.executor.cores\",\"1\") \\\n",
        "    .config(\"spark.python.worker.memory\",\"8g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"spark con\", spark)\n",
        "\n",
        "sc = spark.sparkContext\n",
        "\n",
        "print(spark.sparkContext.getConf().getAll())"
      ],
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": [
        "spark"
      ],
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": [
        "import webbrowser  \n",
        "\n",
        "weburl = sc.uiWebUrl\n",
        "vm_name = weburl.split('//')[1].split('.')[0]\n",
        "port = weburl.split(':')[-1]\n",
        "spark_ui = f'https://{vm_name}-{port}.usgovvirginia.instances.ml.azure.us/'\n",
        "webbrowser.open(spark_ui, new=0)\n",
        "print(f'Spark Web UI URL is: {spark_ui}')"
      ],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "raw",
      "source": [
        "print('done')\n",
        "print('time at stage {:.6}'.format(time.time() - main_start))"
      ],
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": [
        "from pyspark import SparkContext\n",
        "import pyspark"
      ],
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": [
        "list(dataset_dict)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /tmp/workspacezone/TIU_visit_document_note_noXPNA"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": [
        "tiu_doc = spark.read.format(\"parquet\").load('/tmp/workspacezone/TIU_visit_document_note_noXPNA')"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "facd6a95-ea75-4490-9a6d-ff2c0972119c",
          "showTitle": false,
          "title": ""
        }
      }
    },
    {
      "cell_type": "raw",
      "source": [
        "tiu_doc = spark.read.format('parquet').option(\"inferSchema\", \"true\").option(\"header\", \"true\") \\\n",
        "            .load('/tmp/workspacezone/TIU_2022_08_visit_document_note_noXPNA').na.drop(\"all\")"
      ],
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": [
        "tiu_doc.count()"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /tmp/workspacezone/"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "TIU_pull_formask_extended",
      "notebookOrigID": 864597534935248,
      "widgets": {}
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}